import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.stats import kurtosis
from sklearn.impute import KNNImputer
from sklearn.preprocessing import LabelEncoder
from sklearn.utils import resample
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
#!pip install xgboost
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, f1_score, precision_score, recall_score
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings("ignore")
def remove_outliers_iqr(df, columns):
for col in columns:
q1 = df[col].quantile(0.25)
q3 = df[col].quantile(0.75)
iqr = q3 - q1
lower_bound = q1 - 1.5 * iqr
upper_bound = q3 + 1.5 * iqr
df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]
return df
def crear_surrogate_columnas(df, columnas):
for col in columnas:
# Crear una nueva columna con el nombre original seguido de '.surrogate'
nueva_columna = col + '.surrogate'
# Asignar 1 si el valor es nulo y 0 si no lo es
df[nueva_columna] = df[col].isnull().astype(int)
return df
df = pd.read_csv("data-raw/bd_allianz.csv")
df.info()
duplicadas = df[df.duplicated()]
print("\nFilas duplicadas:")
print(duplicadas)
df = df.drop_duplicates()
# Convert to list if it's not already
convertir = df.select_dtypes(exclude=['float64', 'int64']).columns.tolist()
# Add a new element
convertir.extend(['Customer_ID', "Is_direct_debit"])
df[convertir] = df[convertir].apply(lambda x: x.astype('category'))
df.info()
df["Broker_cor"] = df["Broker_cor"].str.replace(',', '').astype("float64")
df.describe()
df.isnull().sum()/df.shape[0]
df["Is_direct_debit"].value_counts()
sns.countplot(data=df, x="Is_direct_debit", hue = "Is_direct_debit")
plt.xlabel("Is Direct Debit")
plt.ylabel("Count")
plt.title("Distribución de cuentas domiciliados")
plt.show()
cat_cols = df.select_dtypes(include = "category").columns
cat_cols = cat_cols.drop(labels=['Broker_account_number', 'Contract_number', 'Customer_ID'],)
#| label: gráficos
#| cache: true
# Set up the figure and axes for six subplots (3 rows, 2 columns)
# Increase the height to allow more space for each subplot
fig, axs = plt.subplots(nrows=6, ncols=1, figsize=(8, 20))  # Adjusted height
# List of the columns to plot
columns = ["Broker_urbanization", "Customer_urbanization", "Broker_province",
"Customer_province", "Customer_age", "Customer_type"]
# Loop through each column and create a countplot
for i, col in enumerate(columns):
sns.countplot(data=df, x=col, hue="Is_direct_debit", ax=axs[i])
axs[i].set_title(f"Distribution of {col}")
axs[i].set_xlabel(col)
axs[i].set_ylabel("Count")
axs[i].set_xticklabels(axs[i].get_xticklabels(), rotation=45, ha='right')
# Adjust layout for better spacing
fig.tight_layout(h_pad=2, w_pad=2)  # Add horizontal padding
# Show the plots
plt.show()
scaler = StandardScaler()
df["Broker_cor_scaled"] = scaler.fit_transform(df[["Broker_cor"]])
plt.figure(figsize=(10, 6))
sns.violinplot(data=df, x="Broker_cor_scaled", hue="Is_direct_debit")
plt.title("Violin Plot of Scaled Broker_cor")
plt.xlabel("Broker_cor_scaled")
plt.show()
df_majority = df[df['Is_direct_debit']==0]
df_minority = df[df['Is_direct_debit']==1]
# muestreo ascendente de la clase minoritaria
df_minority_upsampled = resample(df_minority,
replace=True,     # muesta con reemplazo
n_samples= 357183, # para que coincida con la clase mayoritaria
random_state=0)   # resultados reproducible
# Combinar la clase mayoritaria con la muestra ascendente de la clase minoritaria
df = pd.concat([df_minority_upsampled, df_majority])
plt.figure(figsize=(10, 6))
sns.countplot(data=df, x="Is_direct_debit", hue = "Is_direct_debit")
plt.xlabel("Is Direct Debit")
plt.ylabel("Count")
plt.title("Distribución de cuentas domiciliados")
plt.show()
cat_vars = df.select_dtypes(include = "category").columns
cat_vars
#| label: one hot encoding
#| cache: true
from sklearn.preprocessing import OneHotEncoder
# Instantiate the encoder
encoder = OneHotEncoder(sparse=False, drop="first")  # drop="first" to avoid multicollinearity
# Select columns to encode
categorical_columns = ["Broker_urbanization", "Customer_urbanization", "Broker_province",
"Customer_province", "Customer_age", "Customer_type"]
# Fit and transform the encoder
encoded_data = encoder.fit_transform(df[categorical_columns])
# Convert the encoded data to a DataFrame
encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_columns))
# Concatenate with the original DataFrame, dropping the original categorical columns
df = pd.concat([df.drop(categorical_columns, axis=1), encoded_df], axis=1)
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.stats import kurtosis
from sklearn.impute import KNNImputer
from sklearn.preprocessing import LabelEncoder
from sklearn.utils import resample
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
#!pip install xgboost
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, f1_score, precision_score, recall_score
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings("ignore")
def remove_outliers_iqr(df, columns):
for col in columns:
q1 = df[col].quantile(0.25)
q3 = df[col].quantile(0.75)
iqr = q3 - q1
lower_bound = q1 - 1.5 * iqr
upper_bound = q3 + 1.5 * iqr
df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]
return df
def crear_surrogate_columnas(df, columnas):
for col in columnas:
# Crear una nueva columna con el nombre original seguido de '.surrogate'
nueva_columna = col + '.surrogate'
# Asignar 1 si el valor es nulo y 0 si no lo es
df[nueva_columna] = df[col].isnull().astype(int)
return df
df = pd.read_csv("data-raw/bd_allianz.csv")
df.info()
duplicadas = df[df.duplicated()]
print("\nFilas duplicadas:")
print(duplicadas)
df = df.drop_duplicates()
# Convert to list if it's not already
convertir = df.select_dtypes(exclude=['float64', 'int64']).columns.tolist()
# Add a new element
convertir.extend(['Customer_ID', "Is_direct_debit"])
df[convertir] = df[convertir].apply(lambda x: x.astype('category'))
df.info()
df["Broker_cor"] = df["Broker_cor"].str.replace(',', '').astype("float64")
df.describe()
df.isnull().sum()/df.shape[0]
df["Is_direct_debit"].value_counts()
sns.countplot(data=df, x="Is_direct_debit", hue = "Is_direct_debit")
plt.xlabel("Is Direct Debit")
plt.ylabel("Count")
plt.title("Distribución de cuentas domiciliados")
plt.show()
cat_cols = df.select_dtypes(include = "category").columns
cat_cols = cat_cols.drop(labels=['Broker_account_number', 'Contract_number', 'Customer_ID'],)
#| label: gráficos
#| cache: true
# Set up the figure and axes for six subplots (3 rows, 2 columns)
# Increase the height to allow more space for each subplot
fig, axs = plt.subplots(nrows=6, ncols=1, figsize=(8, 20))  # Adjusted height
# List of the columns to plot
columns = ["Broker_urbanization", "Customer_urbanization", "Broker_province",
"Customer_province", "Customer_age", "Customer_type"]
# Loop through each column and create a countplot
for i, col in enumerate(columns):
sns.countplot(data=df, x=col, hue="Is_direct_debit", ax=axs[i])
axs[i].set_title(f"Distribution of {col}")
axs[i].set_xlabel(col)
axs[i].set_ylabel("Count")
axs[i].set_xticklabels(axs[i].get_xticklabels(), rotation=45, ha='right')
# Adjust layout for better spacing
fig.tight_layout(h_pad=2, w_pad=2)  # Add horizontal padding
# Show the plots
plt.show()
scaler = StandardScaler()
df["Broker_cor_scaled"] = scaler.fit_transform(df[["Broker_cor"]])
plt.figure(figsize=(10, 6))
sns.violinplot(data=df, x="Broker_cor_scaled", hue="Is_direct_debit")
plt.title("Violin Plot of Scaled Broker_cor")
plt.xlabel("Broker_cor_scaled")
plt.show()
df_majority = df[df['Is_direct_debit']==0]
df_minority = df[df['Is_direct_debit']==1]
# muestreo ascendente de la clase minoritaria
df_minority_upsampled = resample(df_minority,
replace=True,     # muesta con reemplazo
n_samples= 357183, # para que coincida con la clase mayoritaria
random_state=0)   # resultados reproducible
# Combinar la clase mayoritaria con la muestra ascendente de la clase minoritaria
df = pd.concat([df_minority_upsampled, df_majority])
plt.figure(figsize=(10, 6))
sns.countplot(data=df, x="Is_direct_debit", hue = "Is_direct_debit")
plt.xlabel("Is Direct Debit")
plt.ylabel("Count")
plt.title("Distribución de cuentas domiciliados")
plt.show()
#| label: one hot encoding
#| cache: true
from sklearn.preprocessing import OneHotEncoder
# Instantiate the encoder
encoder = OneHotEncoder(sparse=False, drop="first")  # drop="first" to avoid multicollinearity
# Select columns to encode
categorical_columns = ["Broker_urbanization", "Customer_urbanization", "Broker_province",
"Customer_province", "Customer_age", "Customer_type"]
# Fit and transform the encoder
encoded_data = encoder.fit_transform(df[categorical_columns])
# Convert the encoded data to a DataFrame
encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_columns))
# Concatenate with the original DataFrame, dropping the original categorical columns
df = pd.concat([df.drop(categorical_columns, axis=1), encoded_df], axis=1)
encoder = OneHotEncoder(sparse=False, drop="first")  # drop="first" to avoid multicollinearity
categorical_columns = ["Broker_urbanization", "Customer_urbanization", "Broker_province",
categorical_columns = ["Broker_urbanization", "Customer_urbanization", "Broker_province",
"Customer_province", "Customer_age", "Customer_type"]
encoded_data = encoder.fit_transform(df[categorical_columns])
from sklearn.preprocessing import OneHotEncoder
encoder = OneHotEncoder(sparse=False, drop="first")  # drop="first" to avoid multicollinearity
from sklearn.preprocessing import OneHotEncoder
encoder = OneHotEncoder(sparse=False, drop="first")  # drop="first" to avoid multicollinearity
encoder = OneHotEncoder(drop="first")  # drop="first" to avoid multicollinearity
categorical_columns = ["Broker_urbanization", "Customer_urbanization", "Broker_province",
categorical_columns = ["Broker_urbanization", "Customer_urbanization", "Broker_province",
"Customer_province", "Customer_age", "Customer_type"]
encoded_data = encoder.fit_transform(df[categorical_columns])
encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_columns))
encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_columns))
df = pd.concat([df.drop(categorical_columns, axis=1), encoded_df], axis=1)
encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_columns))
#| label: one hot encoding
#| cache: true
df_encoded = pd.get_dummies(df, columns=["Broker_urbanization", "Customer_urbanization",
"Broker_province", "Customer_province",
"Customer_age", "Customer_type"])
df.shape
df_encoded.shape
df.columns
df["Broker_account_number"].unique().shape
df = pd.read_csv("data-raw/bd_allianz.csv")
df.info()
df, _ = train_test_split(df, train_size=sample_size, stratify=df["Is_direct_debit"], random_state=42)
duplicadas = df[df.duplicated()]
print("\nFilas duplicadas:")
print(duplicadas)
df = df.drop_duplicates()
df = pd.read_csv("data-raw/bd_allianz.csv")
df.info()
sample_size = 50000
df, _ = train_test_split(df, train_size=sample_size, stratify=df["Is_direct_debit"], random_state=42)
duplicadas = df[df.duplicated()]
print("\nFilas duplicadas:")
print(duplicadas)
df = df.drop_duplicates()
df.shape
cat_vars = df.select_dtypes(include = "category")
cat_vars
reticulate::repl_python()
reticulate::repl_python()
reticulate::repl_python()
reticulate::repl_python()
reticulate::repl_python()
reticulate::repl_python()
reticulate::repl_python()
reticulate::repl_python()
reticulate::repl_python()
reticulate::repl_python()
reticulate::repl_python()
reticulate::repl_python()
reticulate::repl_python()
reticulate::repl_python()
reticulate::repl_python()
gc()
reticulate::repl_python()
reticulate::repl_python()
reticulate::repl_python()
reticulate::repl_python()
reticulate::repl_python()
reticulate::repl_python()
reticulate::repl_python()
reticulate::repl_python()
reticulate::repl_python()
