---
title: "Caso Allianz"
format:
  html:
    embed-resources: true
---

## Librer√≠as

```{python}
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.stats import kurtosis
from sklearn.impute import KNNImputer
from sklearn.preprocessing import LabelEncoder
from sklearn.utils import resample
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
#!pip install xgboost
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, f1_score, precision_score, recall_score
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import OneHotEncoder
from scipy.sparse import hstack
from sklearn.compose import ColumnTransformer
from scipy.sparse import save_npz
from scipy.sparse import load_npz
from sklearn.feature_selection import SelectKBest, chi2


import warnings 
warnings.filterwarnings("ignore")
```

```{python}
sparse_matrix = load_npz("data/encoded_data_sparse.npz")

# Step 2: Load column names
column_names = pd.read_csv("data/column_names.csv")["column_names"].tolist()

# Step 3: Create a sparse DataFrame with loaded data and column names
encoded_df = pd.DataFrame.sparse.from_spmatrix(sparse_matrix, columns=column_names)

encoded_df = encoded_df.drop("Payment_frequency_Monthly", axis=1)
```


```{python}
from sklearn.feature_selection import SelectKBest, chi2

X = encoded_df.drop('Is_direct_debit', axis=1)
y = encoded_df['Is_direct_debit']
X_positive = X.apply(lambda x: x + abs(x.min()) if x.min() < 0 else x)
```


```{python}
from sklearn.feature_selection import VarianceThreshold

# Remove features with very low variance
selector = VarianceThreshold(threshold=0.001)
X_reduced = selector.fit_transform(X)
selected_columns = X_positive.columns[selector.get_support(indices=True)]
```


```{python}
from sklearn.ensemble import RandomForestClassifier
import numpy as np

# Initialize Random Forest with parallel processing
rf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)
rf.fit(X_reduced, y)

# Get feature importances
importances = rf.feature_importances_

# Select top K features
k = 10
indices = np.argsort(importances)[::-1][:k]
selected_features = selected_columns[indices]

print("Selected Features:")
print(selected_features)

```